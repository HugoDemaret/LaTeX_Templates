\section*{Préliminaires}

{\textbf{Information : }
\textcolor{universitycomp}{Chaque fichier C++ porte le nom de la partie, puis de l'exercice séparé par un underscore "\_". Exemple : \texttt{coloriage\_3.cpp} pour l'exercice 3 de la partie coloriage.}}

\begin{definition}[Complexité]
    Par \textbf{complexité en temps} d'un algorithme $A$, on entend le nombre d'opérations élémentaires (comparaison, addition, soustraction, multiplication, division, affectation, test, etc.) nécessaires à l'exécution de $A$ dans le pire cas.
\end{definition}
Lorsque la complexité en temps dépend d'un ou plusieurs paramètres $k_1,...,k_r$, on dit qu'elle est en $\comp{f(k_1,...,k_r)}$ s'il existe une constante $C>0$ telle que, pour toutes valeurs de $k_1,...,k_r$ suffisament grandes (c'est-à-dire plus grandes qu'un certain seuil), la complexité est au plus $C \times f(k_1,...,k_r)$.
\\
On dit que la complexité en temps est \textbf{linéaire} quand $f$ est une fonction linéaire des paramères $k_1,...,k_r$, \textbf{polynomiale}
quand $f$ est une fonction polynomiale de paramètre $k_1,...,k_r$, et enfin exponentielle quand $f = 2^g$, où $g$ est une fonction polynomiale des paramètres $k_1,...,k_r$.
\\
Dans ce sujet, nous justifierons la complexité en temps des algorithmes.

\begin{definition}[Graphe]
        
\end{definition}